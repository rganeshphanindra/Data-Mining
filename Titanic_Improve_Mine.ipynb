{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b2044c-e6e6-47ca-a779-a3b8cdedff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fed432-5b01-4ffd-8a96-39ee7898e7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "Sample Records from Training Data:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "Test Dataset Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n",
      "\n",
      "Sample Records from Test Data:\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the training dataset\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# Read the test dataset\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Display metadata for the training dataset\n",
    "print(\"Training Dataset Summary:\")\n",
    "train_data.info()\n",
    "\n",
    "# Preview the first few entries in the training dataset\n",
    "print(\"\\nSample Records from Training Data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Display metadata for the test dataset\n",
    "print(\"\\nTest Dataset Summary:\")\n",
    "test_data.info()\n",
    "\n",
    "# Preview the first few entries in the test dataset\n",
    "print(\"\\nSample Records from Test Data:\")\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c71faaa-463a-48e5-ad46-b1ff67f85954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\Ganesh Phanindra\\AppData\\Local\\Temp\\ipykernel_13540\\3552638650.py:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  title_search = re.search(' ([A-Za-z]+)\\.', name)\n"
     ]
    }
   ],
   "source": [
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def map_title(title):\n",
    "    title_mapping = {\n",
    "        \"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4,\n",
    "        \"Dr\": 5, \"Rev\": 5, \"Col\": 5, \"Major\": 5, \"Mlle\": 2,\n",
    "        \"Countess\": 5, \"Ms\": 2, \"Lady\": 5, \"Jonkheer\": 5,\n",
    "        \"Don\": 5, \"Dona\": 5, \"Mme\": 3, \"Capt\": 5, \"Sir\": 5\n",
    "    }\n",
    "    return title_mapping.get(title, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e023eea-8e91-454c-b3ef-8905322e3ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting titles from names...\n",
      "Unique titles in training data: ['Mr' 'Mrs' 'Miss' 'Master' 'Don' 'Rev' 'Dr' 'Mme' 'Ms' 'Major' 'Lady'\n",
      " 'Sir' 'Mlle' 'Col' 'Capt' 'Countess' 'Jonkheer']\n",
      "Unique titles in test data: ['Mr' 'Mrs' 'Miss' 'Master' 'Ms' 'Col' 'Rev' 'Dr' 'Dona']\n",
      "\n",
      "Mapping titles to numeric values...\n",
      "\n",
      "Training data sample with updated titles:\n",
      "                                                Name  Title\n",
      "0                            Braund, Mr. Owen Harris      1\n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      3\n",
      "2                             Heikkinen, Miss. Laina      2\n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      3\n",
      "4                           Allen, Mr. William Henry      1\n",
      "\n",
      "Test data sample with updated titles:\n",
      "                                           Name  Title\n",
      "0                              Kelly, Mr. James      1\n",
      "1              Wilkes, Mrs. James (Ellen Needs)      3\n",
      "2                     Myles, Mr. Thomas Francis      1\n",
      "3                              Wirz, Mr. Albert      1\n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)      3\n",
      "\n",
      "Title distribution in training data:\n",
      "Title\n",
      "1    517\n",
      "2    185\n",
      "3    126\n",
      "4     40\n",
      "5     23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Title distribution in test data:\n",
      "Title\n",
      "1    240\n",
      "2     79\n",
      "3     72\n",
      "4     21\n",
      "5      6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saving updated datasets...\n",
      "Files saved: 'train_updated.csv' and 'test_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Extract title from the 'Name' column\n",
    "print(\"Extracting titles from names...\")\n",
    "train_data[\"Title\"] = train_data[\"Name\"].apply(get_title)\n",
    "test_data[\"Title\"] = test_data[\"Name\"].apply(get_title)\n",
    "\n",
    "# Display unique titles found in each dataset\n",
    "print(f\"Unique titles in training data: {train_data['Title'].unique()}\")\n",
    "print(f\"Unique titles in test data: {test_data['Title'].unique()}\")\n",
    "\n",
    "# Convert extracted titles to numerical categories\n",
    "print(\"\\nMapping titles to numeric values...\")\n",
    "train_data[\"Title\"] = train_data[\"Title\"].apply(map_title)\n",
    "test_data[\"Title\"] = test_data[\"Title\"].apply(map_title)\n",
    "\n",
    "# Preview the first few entries to ensure correct processing\n",
    "print(\"\\nTraining data sample with updated titles:\")\n",
    "print(train_data[[\"Name\", \"Title\"]].head())\n",
    "\n",
    "print(\"\\nTest data sample with updated titles:\")\n",
    "print(test_data[[\"Name\", \"Title\"]].head())\n",
    "\n",
    "# Display the distribution of title categories\n",
    "print(\"\\nTitle distribution in training data:\")\n",
    "print(train_data[\"Title\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nTitle distribution in test data:\")\n",
    "print(test_data[\"Title\"].value_counts().sort_index())\n",
    "\n",
    "# Save the modified datasets to CSV files\n",
    "print(\"\\nSaving updated datasets...\")\n",
    "train_data.to_csv(\"train_updated.csv\", index=False)\n",
    "test_data.to_csv(\"test_updated.csv\", index=False)\n",
    "\n",
    "print(\"Files saved: 'train_updated.csv' and 'test_updated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe764f5-f35f-40ab-b4a0-231de3b139fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of training data with encoded 'Sex' column:\n",
      "   PassengerId  Sex   Age  Survived\n",
      "0            1    1  22.0         0\n",
      "1            2    0  38.0         1\n",
      "2            3    0  26.0         1\n",
      "3            4    0  35.0         1\n",
      "4            5    1  35.0         0\n",
      "\n",
      "Preview of test data with encoded 'Sex' column:\n",
      "   PassengerId  Sex   Age\n",
      "0          892    1  34.5\n",
      "1          893    0  47.0\n",
      "2          894    1  62.0\n",
      "3          895    1  27.0\n",
      "4          896    0  22.0\n",
      "\n",
      "Sex distribution in training dataset:\n",
      "Sex\n",
      "1    577\n",
      "0    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sex distribution in test dataset:\n",
      "Sex\n",
      "1    266\n",
      "0    152\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distinct values in 'Sex' column (train): [1 0]\n",
      "Distinct values in 'Sex' column (test): [1 0]\n",
      "\n",
      "Processed datasets successfully saved as 'train_updated.csv' and 'test_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "# Function to encode 'Sex' column into numerical values\n",
    "def sex_to_numeric(sex):\n",
    "    return 1 if sex == 'male' else 0\n",
    "\n",
    "# Transform 'Sex' column in both datasets\n",
    "train_data[\"Sex\"] = train_data[\"Sex\"].apply(sex_to_numeric)\n",
    "test_data[\"Sex\"] = test_data[\"Sex\"].apply(sex_to_numeric)\n",
    "\n",
    "# Preview data after transformation\n",
    "print(\"Preview of training data with encoded 'Sex' column:\")\n",
    "print(train_data[[\"PassengerId\", \"Sex\", \"Age\", \"Survived\"]].head())\n",
    "\n",
    "print(\"\\nPreview of test data with encoded 'Sex' column:\")\n",
    "print(test_data[[\"PassengerId\", \"Sex\", \"Age\"]].head())\n",
    "\n",
    "# Display distribution of encoded 'Sex' values\n",
    "print(\"\\nSex distribution in training dataset:\")\n",
    "print(train_data[\"Sex\"].value_counts())\n",
    "\n",
    "print(\"\\nSex distribution in test dataset:\")\n",
    "print(test_data[\"Sex\"].value_counts())\n",
    "\n",
    "# Confirm unique values in the 'Sex' column\n",
    "print(\"\\nDistinct values in 'Sex' column (train):\", train_data[\"Sex\"].unique())\n",
    "print(\"Distinct values in 'Sex' column (test):\", test_data[\"Sex\"].unique())\n",
    "\n",
    "# Save the processed datasets\n",
    "train_data.to_csv(\"train_updated.csv\", index=False)\n",
    "test_data.to_csv(\"test_updated.csv\", index=False)\n",
    "\n",
    "print(\"\\nProcessed datasets successfully saved as 'train_updated.csv' and 'test_updated.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "900c937b-a60c-43dc-9bf0-766df9ed04fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of training data with 'FamilySize' column added:\n",
      "   PassengerId  SibSp  Parch  FamilySize\n",
      "0            1      1      0           2\n",
      "1            2      1      0           2\n",
      "2            3      0      0           1\n",
      "3            4      1      0           2\n",
      "4            5      0      0           1\n",
      "\n",
      "Sample of test data with 'FamilySize' column added:\n",
      "   PassengerId  SibSp  Parch  FamilySize\n",
      "0          892      0      0           1\n",
      "1          893      1      0           2\n",
      "2          894      0      0           1\n",
      "3          895      0      0           1\n",
      "4          896      1      1           3\n",
      "\n",
      "Family size distribution in the training dataset:\n",
      "FamilySize\n",
      "1     537\n",
      "2     161\n",
      "3     102\n",
      "4      29\n",
      "5      15\n",
      "6      22\n",
      "7      12\n",
      "8       6\n",
      "11      7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Family size distribution in the test dataset:\n",
      "FamilySize\n",
      "1     253\n",
      "2      74\n",
      "3      57\n",
      "4      14\n",
      "5       7\n",
      "6       3\n",
      "7       4\n",
      "8       2\n",
      "11      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "The processed datasets have been successfully saved as 'train_updated.csv' and 'test_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "# Function to compute the family size for each passenger\n",
    "def calculate_family_size(row):\n",
    "    return row[\"SibSp\"] + row[\"Parch\"] + 1  # Including the passenger themselves\n",
    "\n",
    "# Generate the 'FamilySize' column for both datasets\n",
    "train_data[\"FamilySize\"] = train_data.apply(calculate_family_size, axis=1)\n",
    "test_data[\"FamilySize\"] = test_data.apply(calculate_family_size, axis=1)\n",
    "\n",
    "# Preview data to verify the new column\n",
    "print(\"Sample of training data with 'FamilySize' column added:\")\n",
    "print(train_data[[\"PassengerId\", \"SibSp\", \"Parch\", \"FamilySize\"]].head())\n",
    "\n",
    "print(\"\\nSample of test data with 'FamilySize' column added:\")\n",
    "print(test_data[[\"PassengerId\", \"SibSp\", \"Parch\", \"FamilySize\"]].head())\n",
    "\n",
    "# Display the distribution of family sizes\n",
    "print(\"\\nFamily size distribution in the training dataset:\")\n",
    "print(train_data[\"FamilySize\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nFamily size distribution in the test dataset:\")\n",
    "print(test_data[\"FamilySize\"].value_counts().sort_index())\n",
    "\n",
    "# Save the processed datasets to CSV files\n",
    "train_data.to_csv(\"train_updated.csv\", index=False)\n",
    "test_data.to_csv(\"test_updated.csv\", index=False)\n",
    "\n",
    "print(\"\\nThe processed datasets have been successfully saved as 'train_updated.csv' and 'test_updated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5880e6e1-3be5-4ab7-9aa4-acdafa380bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial columns in training dataset: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'FamilySize']\n",
      "Initial columns in test dataset: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'FamilySize']\n",
      "\n",
      "Columns remaining in training dataset after removal: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize']\n",
      "Columns remaining in test dataset after removal: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize']\n",
      "\n",
      "Sample rows from training dataset post-modification:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name  Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
      "\n",
      "      Fare Embarked  Title  FamilySize  \n",
      "0   7.2500        S      1           2  \n",
      "1  71.2833        C      3           2  \n",
      "2   7.9250        S      2           1  \n",
      "3  53.1000        S      3           2  \n",
      "4   8.0500        S      1           1  \n",
      "\n",
      "Sample rows from test dataset post-modification:\n",
      "   PassengerId  Pclass                                          Name  Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    1   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
      "3          895       3                              Wirz, Mr. Albert    1   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
      "\n",
      "    Age  SibSp  Parch     Fare Embarked  Title  FamilySize  \n",
      "0  34.5      0      0   7.8292        Q      1           1  \n",
      "1  47.0      1      0   7.0000        S      3           2  \n",
      "2  62.0      0      0   9.6875        Q      1           1  \n",
      "3  27.0      0      0   8.6625        S      1           1  \n",
      "4  22.0      1      1  12.2875        S      3           3  \n",
      "\n",
      "The modified datasets have been successfully stored as 'train_updated.csv' and 'test_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "# Display the original column names before modifications\n",
    "print(\"Initial columns in training dataset:\", train_data.columns.tolist())\n",
    "print(\"Initial columns in test dataset:\", test_data.columns.tolist())\n",
    "\n",
    "# Specify columns to be dropped and remove them from both datasets\n",
    "columns_to_drop = [\"Cabin\", \"Ticket\"]\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "test_data = test_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Confirm column removal by displaying the updated column lists\n",
    "print(\"\\nColumns remaining in training dataset after removal:\", train_data.columns.tolist())\n",
    "print(\"Columns remaining in test dataset after removal:\", test_data.columns.tolist())\n",
    "\n",
    "# Display a preview of the modified datasets\n",
    "print(\"\\nSample rows from training dataset post-modification:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nSample rows from test dataset post-modification:\")\n",
    "print(test_data.head())\n",
    "\n",
    "# Save the processed datasets to new CSV files\n",
    "train_data.to_csv(\"train_updated.csv\", index=False)\n",
    "test_data.to_csv(\"test_updated.csv\", index=False)\n",
    "\n",
    "print(\"\\nThe modified datasets have been successfully stored as 'train_updated.csv' and 'test_updated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d4f67e-73a9-4098-aada-5e472f73c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Age column (train) before filling: 177\n",
      "Missing values in Age column (test) before filling: 86\n",
      "\n",
      "Missing values in Age column (train) after filling: 0\n",
      "Missing values in Age column (test) after filling: 0\n",
      "\n",
      "Sample rows from training dataset after handling Age:\n",
      "   PassengerId   Age\n",
      "0            1  22.0\n",
      "1            2  38.0\n",
      "2            3  26.0\n",
      "3            4  35.0\n",
      "4            5  35.0\n",
      "\n",
      "Sample rows from test dataset after handling Age:\n",
      "   PassengerId   Age\n",
      "0          892  34.5\n",
      "1          893  47.0\n",
      "2          894  62.0\n",
      "3          895  27.0\n",
      "4          896  22.0\n",
      "\n",
      "Processed datasets have been successfully saved as 'train_updated.csv' and 'test_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "# Check and display the count of missing values in the Age column before imputation\n",
    "print(\"Missing values in Age column (train) before filling:\", train_data[\"Age\"].isna().sum())\n",
    "print(\"Missing values in Age column (test) before filling:\", test_data[\"Age\"].isna().sum())\n",
    "\n",
    "# Replace null values in the Age column with 29\n",
    "train_data[\"Age\"] = train_data[\"Age\"].fillna(29)\n",
    "test_data[\"Age\"] = test_data[\"Age\"].fillna(29)\n",
    "\n",
    "# Confirm and display the count of missing values in Age column after imputation\n",
    "print(\"\\nMissing values in Age column (train) after filling:\", train_data[\"Age\"].isna().sum())\n",
    "print(\"Missing values in Age column (test) after filling:\", test_data[\"Age\"].isna().sum())\n",
    "\n",
    "# Preview the updated data\n",
    "print(\"\\nSample rows from training dataset after handling Age:\")\n",
    "print(train_data[[\"PassengerId\", \"Age\"]].head())\n",
    "\n",
    "print(\"\\nSample rows from test dataset after handling Age:\")\n",
    "print(test_data[[\"PassengerId\", \"Age\"]].head())\n",
    "\n",
    "# Save the modified datasets\n",
    "train_data.to_csv(\"train_updated.csv\", index=False)\n",
    "test_data.to_csv(\"test_updated.csv\", index=False)\n",
    "\n",
    "print(\"\\nProcessed datasets have been successfully saved as 'train_updated.csv' and 'test_updated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53476060-f92d-4bc6-a853-c44d07bfdc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of training data with Age categories:\n",
      "   PassengerId  Age\n",
      "0            1    1\n",
      "1            2    2\n",
      "2            3    2\n",
      "3            4    2\n",
      "4            5    2\n",
      "\n",
      "First few rows of test data with Age categories:\n",
      "   PassengerId  Age\n",
      "0          892    2\n",
      "1          893    2\n",
      "2          894    3\n",
      "3          895    2\n",
      "4          896    1\n",
      "\n",
      "Age category distribution in training data:\n",
      "Age\n",
      "1    301\n",
      "2    526\n",
      "3     63\n",
      "4      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Age category distribution in test data:\n",
      "Age\n",
      "1    142\n",
      "2    245\n",
      "3     30\n",
      "4      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "# Function to assign age category based on age range\n",
    "def assign_age_category(age):\n",
    "    if 0 <= age <= 25:\n",
    "        return 1\n",
    "    elif 26 <= age <= 50:\n",
    "        return 2\n",
    "    elif 51 <= age <= 75:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "# Apply the function to both training and test datasets to categorize 'Age'\n",
    "train_data['Age'] = train_data['Age'].apply(assign_age_category)\n",
    "test_data['Age'] = test_data['Age'].apply(assign_age_category)\n",
    "\n",
    "# Display the first few rows of both datasets to verify the new Age categories\n",
    "print(\"First few rows of training data with Age categories:\")\n",
    "print(train_data[['PassengerId', 'Age']].head())\n",
    "\n",
    "print(\"\\nFirst few rows of test data with Age categories:\")\n",
    "print(test_data[['PassengerId', 'Age']].head())\n",
    "\n",
    "# Show the distribution of the new Age categories in the training dataset\n",
    "print(\"\\nAge category distribution in training data:\")\n",
    "print(train_data['Age'].value_counts().sort_index())\n",
    "\n",
    "# Show the distribution of the new Age categories in the test dataset\n",
    "print(\"\\nAge category distribution in test data:\")\n",
    "print(test_data['Age'].value_counts().sort_index())\n",
    "\n",
    "# Save the modified datasets to CSV\n",
    "train_data.to_csv('train_updated.csv', index=False)\n",
    "test_data.to_csv('test_updated.csv', index=False)\n",
    "\n",
    "print(\"\\nUpdated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e5e346a-58a0-445b-b77b-2fd1af028257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns in the training dataset: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize']\n",
      "Original columns in the test dataset: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize']\n",
      "\n",
      "Columns in the training dataset after removing 'Fare': ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Title', 'FamilySize']\n",
      "Columns in the test dataset after removing 'Fare': ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Title', 'FamilySize']\n",
      "\n",
      "Sample rows from the training dataset after column removal:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name  Sex  Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris    1    1      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0    2      1      0   \n",
      "2                             Heikkinen, Miss. Laina    0    2      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0    2      1      0   \n",
      "4                           Allen, Mr. William Henry    1    2      0      0   \n",
      "\n",
      "  Embarked  Title  FamilySize  \n",
      "0        S      1           2  \n",
      "1        C      3           2  \n",
      "2        S      2           1  \n",
      "3        S      3           2  \n",
      "4        S      1           1  \n",
      "\n",
      "Sample rows from the test dataset after column removal:\n",
      "   PassengerId  Pclass                                          Name  Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    1   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
      "3          895       3                              Wirz, Mr. Albert    1   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
      "\n",
      "   Age  SibSp  Parch Embarked  Title  FamilySize  \n",
      "0    2      0      0        Q      1           1  \n",
      "1    2      1      0        S      3           2  \n",
      "2    3      0      0        Q      1           1  \n",
      "3    2      0      0        S      1           1  \n",
      "4    1      1      1        S      3           3  \n",
      "\n",
      "The datasets have been successfully saved as 'train_updated.csv' and 'test_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "# Display the original column names in both datasets\n",
    "print(\"Original columns in the training dataset:\", train_data.columns.tolist())\n",
    "print(\"Original columns in the test dataset:\", test_data.columns.tolist())\n",
    "\n",
    "# Remove the 'Fare' column from both the training and test datasets\n",
    "train_data.drop('Fare', axis=1, inplace=True)\n",
    "test_data.drop('Fare', axis=1, inplace=True)\n",
    "\n",
    "# Show the updated column names after removing 'Fare'\n",
    "print(\"\\nColumns in the training dataset after removing 'Fare':\", train_data.columns.tolist())\n",
    "print(\"Columns in the test dataset after removing 'Fare':\", test_data.columns.tolist())\n",
    "\n",
    "# Show the first few rows of both datasets to verify the removal\n",
    "print(\"\\nSample rows from the training dataset after column removal:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nSample rows from the test dataset after column removal:\")\n",
    "print(test_data.head())\n",
    "\n",
    "# Save the modified datasets to CSV files\n",
    "train_data.to_csv('train_updated.csv', index=False)\n",
    "test_data.to_csv('test_updated.csv', index=False)\n",
    "\n",
    "print(\"\\nThe datasets have been successfully saved as 'train_updated.csv' and 'test_updated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "713321fd-bdf8-41a8-aaf8-39fd07b5e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial columns in the training dataset: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Title', 'FamilySize']\n",
      "Initial columns in the test dataset: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Title', 'FamilySize']\n",
      "\n",
      "Columns in the training dataset after removal: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
      "Columns in the test dataset after removal: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
      "\n",
      "Sample rows from the training dataset after column removal:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name  Sex  Age Embarked  \\\n",
      "0                            Braund, Mr. Owen Harris    1    1        S   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0    2        C   \n",
      "2                             Heikkinen, Miss. Laina    0    2        S   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0    2        S   \n",
      "4                           Allen, Mr. William Henry    1    2        S   \n",
      "\n",
      "   Title  FamilySize  \n",
      "0      1           2  \n",
      "1      3           2  \n",
      "2      2           1  \n",
      "3      3           2  \n",
      "4      1           1  \n",
      "\n",
      "Sample rows from the test dataset after column removal:\n",
      "   PassengerId  Pclass                                          Name  Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    1   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
      "3          895       3                              Wirz, Mr. Albert    1   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
      "\n",
      "   Age Embarked  Title  FamilySize  \n",
      "0    2        Q      1           1  \n",
      "1    2        S      3           2  \n",
      "2    3        Q      1           1  \n",
      "3    2        S      1           1  \n",
      "4    1        S      3           3  \n",
      "\n",
      "Updated datasets have been successfully saved as 'train_updated.csv' and 'test_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "# Print the original column names in both datasets\n",
    "print(\"Initial columns in the training dataset:\", train_data.columns.tolist())\n",
    "print(\"Initial columns in the test dataset:\", test_data.columns.tolist())\n",
    "\n",
    "# Columns to be removed from both datasets\n",
    "columns_to_remove = ['Fare', 'SibSp', 'Parch', 'TitleNum', 'AgeCategory']\n",
    "\n",
    "# Remove the specified columns, ignoring errors if they don't exist\n",
    "train_data.drop(columns=columns_to_remove, errors='ignore', inplace=True)\n",
    "test_data.drop(columns=columns_to_remove, errors='ignore', inplace=True)\n",
    "\n",
    "# Print the updated column names to verify the changes\n",
    "print(\"\\nColumns in the training dataset after removal:\", train_data.columns.tolist())\n",
    "print(\"Columns in the test dataset after removal:\", test_data.columns.tolist())\n",
    "\n",
    "# Show the first few rows to confirm the removal of columns\n",
    "print(\"\\nSample rows from the training dataset after column removal:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nSample rows from the test dataset after column removal:\")\n",
    "print(test_data.head())\n",
    "\n",
    "# Save the updated datasets to CSV files\n",
    "train_data.to_csv('train_updated.csv', index=False)\n",
    "test_data.to_csv('test_updated.csv', index=False)\n",
    "\n",
    "print(\"\\nUpdated datasets have been successfully saved as 'train_updated.csv' and 'test_updated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d43f32c-4662-41d8-b5da-c9b995185d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial columns in the training dataset: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
      "Initial columns in the test dataset: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
      "\n",
      "Columns in the training dataset after removal: ['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
      "Columns in the test dataset after removal: ['PassengerId', 'Pclass', 'Sex', 'Age', 'Embarked', 'Title', 'FamilySize']\n",
      "\n",
      "Preview of the training dataset after column removal:\n",
      "   PassengerId  Survived  Pclass  Sex  Age Embarked  Title  FamilySize\n",
      "0            1         0       3    1    1        S      1           2\n",
      "1            2         1       1    0    2        C      3           2\n",
      "2            3         1       3    0    2        S      2           1\n",
      "3            4         1       1    0    2        S      3           2\n",
      "4            5         0       3    1    2        S      1           1\n",
      "\n",
      "Preview of the test dataset after column removal:\n",
      "   PassengerId  Pclass  Sex  Age Embarked  Title  FamilySize\n",
      "0          892       3    1    2        Q      1           1\n",
      "1          893       3    0    2        S      3           2\n",
      "2          894       2    1    3        Q      1           1\n",
      "3          895       3    1    2        S      1           1\n",
      "4          896       3    0    1        S      3           3\n",
      "\n",
      "Modified datasets have been successfully saved as 'train_updated.csv' and 'test_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "# Print initial column names from both training and test datasets\n",
    "print(\"Initial columns in the training dataset:\", train_data.columns.tolist())\n",
    "print(\"Initial columns in the test dataset:\", test_data.columns.tolist())\n",
    "\n",
    "# Remove the 'Name' column from both datasets\n",
    "train_data.drop(columns=['Name'], inplace=True)\n",
    "test_data.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "# Print updated column names to verify the change\n",
    "print(\"\\nColumns in the training dataset after removal:\", train_data.columns.tolist())\n",
    "print(\"Columns in the test dataset after removal:\", test_data.columns.tolist())\n",
    "\n",
    "# Display the first few rows to ensure the column removal was successful\n",
    "print(\"\\nPreview of the training dataset after column removal:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nPreview of the test dataset after column removal:\")\n",
    "print(test_data.head())\n",
    "\n",
    "# Save the modified datasets to CSV files\n",
    "train_data.to_csv('train_updated.csv', index=False)\n",
    "test_data.to_csv('test_updated.csv', index=False)\n",
    "\n",
    "print(\"\\nModified datasets have been successfully saved as 'train_updated.csv' and 'test_updated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab5db72a-3a30-4cb6-9f3c-095ece66c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of training data with updated 'Embarked' column:\n",
      "   PassengerId  Embarked\n",
      "0            1         1\n",
      "1            2         3\n",
      "2            3         1\n",
      "3            4         1\n",
      "4            5         1\n",
      "\n",
      "Preview of test data with updated 'Embarked' column:\n",
      "   PassengerId  Embarked\n",
      "0          892         2\n",
      "1          893         1\n",
      "2          894         2\n",
      "3          895         1\n",
      "4          896         1\n",
      "\n",
      "Frequency of 'Embarked' values in the training dataset:\n",
      "Embarked\n",
      "0      2\n",
      "1    644\n",
      "2     77\n",
      "3    168\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frequency of 'Embarked' values in the test dataset:\n",
      "Embarked\n",
      "1    270\n",
      "2     46\n",
      "3    102\n",
      "Name: count, dtype: int64\n",
      "\n",
      "The updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "# Function to map Embarked values to numeric codes\n",
    "def map_embarked(value):\n",
    "    mapping = {'S': 1, 'Q': 2, 'C': 3}\n",
    "    return mapping.get(value, 0)  # Default to 0 for any unknown values\n",
    "\n",
    "# Apply the mapping to the 'Embarked' column in both datasets\n",
    "train_data['Embarked'] = train_data['Embarked'].map(map_embarked)\n",
    "test_data['Embarked'] = test_data['Embarked'].map(map_embarked)\n",
    "\n",
    "# Show the first few rows to confirm the changes\n",
    "print(\"Preview of training data with updated 'Embarked' column:\")\n",
    "print(train_data[['PassengerId', 'Embarked']].head())\n",
    "\n",
    "print(\"\\nPreview of test data with updated 'Embarked' column:\")\n",
    "print(test_data[['PassengerId', 'Embarked']].head())\n",
    "\n",
    "# Display the distribution of 'Embarked' values in the training dataset\n",
    "print(\"\\nFrequency of 'Embarked' values in the training dataset:\")\n",
    "print(train_data['Embarked'].value_counts().sort_index())\n",
    "\n",
    "# Display the distribution of 'Embarked' values in the test dataset\n",
    "print(\"\\nFrequency of 'Embarked' values in the test dataset:\")\n",
    "print(test_data['Embarked'].value_counts().sort_index())\n",
    "\n",
    "# Save the modified datasets to new CSV files\n",
    "train_data.to_csv('train_updated.csv', index=False)\n",
    "test_data.to_csv('test_updated.csv', index=False)\n",
    "\n",
    "print(\"\\nThe updated datasets have been saved as 'train_updated.csv' and 'test_updated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5b30870-3647-4b1a-bbe3-e76397ab32c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracies of the models (from highest to lowest):\n",
      "Decision Tree Classifier: 100.0%\n",
      "Random Forest Classifier: 99.89%\n",
      "KNN Classifier: 85.86%\n",
      "SVM: 83.73%\n",
      "Logistic Regression: 80.7%\n",
      "Naive Bayes Classifier: 80.58%\n",
      "Linear SVC Model: 80.36%\n",
      "Perceptron Model: 79.35%\n",
      "SGD Classifier: 74.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ganesh Phanindra\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "train_set = pd.read_csv('train_updated.csv')\n",
    "test_set = pd.read_csv('test_updated.csv')\n",
    "\n",
    "# Separate features and target for training dataset\n",
    "X_train_set = train_set.drop('Survived', axis=1)\n",
    "y_train_set = train_set['Survived']\n",
    "\n",
    "# Prepare the test dataset\n",
    "X_test_set = test_set.copy()\n",
    "\n",
    "# Feature scaling\n",
    "scaler_tool = StandardScaler()\n",
    "X_train_scaled_set = scaler_tool.fit_transform(X_train_set)\n",
    "X_test_scaled_set = scaler_tool.transform(X_test_set)\n",
    "\n",
    "# Define the models\n",
    "classification_models = {\n",
    "    'SVM': SVC(),\n",
    "    'KNN Classifier': KNeighborsClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=100),\n",
    "    'Naive Bayes Classifier': GaussianNB(),\n",
    "    'Perceptron Model': Perceptron(),\n",
    "    'SGD Classifier': SGDClassifier(),\n",
    "    'Linear SVC Model': LinearSVC(),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Train the models and record the accuracies\n",
    "model_accuracies = {}\n",
    "for model_name, classifier in classification_models.items():\n",
    "    classifier.fit(X_train_scaled_set, y_train_set)\n",
    "    accuracy_score = round(classifier.score(X_train_scaled_set, y_train_set) * 100, 2)\n",
    "    model_accuracies[model_name] = accuracy_score\n",
    "\n",
    "# Sort the accuracy scores in descending order\n",
    "sorted_model_accuracies = dict(sorted(model_accuracies.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Display the sorted accuracies\n",
    "print(\"\\nAccuracies of the models (from highest to lowest):\")\n",
    "for model_name, accuracy in sorted_model_accuracies.items():\n",
    "    print(f\"{model_name}: {accuracy}%\")\n",
    "\n",
    "# Optional: Make predictions using the model with the highest accuracy (Random Forest assumed to be the best)\n",
    "best_classifier = classification_models['Random Forest Classifier']\n",
    "predicted_values = best_classifier.predict(X_test_scaled_set)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission_file = pd.DataFrame({\n",
    "    'PassengerId': test_set['PassengerId'],\n",
    "    'Survived': predicted_values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4914f05-c9b5-4045-910e-e669df96b955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f137d-b04a-4580-ace7-f97441823294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
